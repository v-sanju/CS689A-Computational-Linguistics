Name - Sanjeev Kumar
Roll No - 231110044


Question 1: 
	All 25 questions answered and are in python notebook.
Question 2:
	In question 2, I have two python notebooks named as "indicNER fine tuned" and "indicBERT fine tuned"
	indicNER fine tuned	:
		1) First installed all the dependencies.
		2) Imported pre_trained indicNER model to show an example of how NER tagging works.
		3) Downloaded Naampadam dataset for hindi language.
		4) Selected 20000 lines of training dataset for our training.
		5) Imported pre_trained indicNER model for fine-tuning.
		6) tokenized and aligned to corresponding annotated NER tags for train_data, validation_data.
		7) Set the hyper_parameters to be used for training.
		8) Created trainer() object and trained as per set hyper-parameters.
		9) Recorded the training and validataion result.
		10) Checked and recorded performance on test_data as asked.
		11) Repeated 7 to 10 one more time.
		12) Using this trained model, generated NER tags for 25 sentences and saved them as pickel file for using in Q4.
		
	indicBERT fine tuned	:
		1) First installed all the dependencies.
		2) Imported pre_trained indicNER model to show an example of how NER tagging works.
		3) Downloaded Naampadam dataset for hindi language.
		4) Selected 20000 lines of training dataset for our training.
		5) Imported pre_trained indicBERT model for fine-tuning.
		6) tokenized and aligned to corresponding annotated NER tags for train_data, validation_data.
		7) Set the hyper_parameters to be used for training.
		8) Created trainer() object and trained as per set hyper-parameters.
		9) Recorded the training and validataion result.
		10) Checked and recorded performance on test_data as asked.
		11) Repeated 7 to 10 one more time.
		12) Using this trained model, generated NER tags for 25 sentences and saved them as pickel file for using in Q4.
Question 3:
	All 25 questions answered and are in python notebook.
Question 4:
	Evaluation of indicNER	:
		Imported NER tags pickel file generated by indicNER fine-tuned model while doing Question 2 for the said 25 questions.
		Using sicket-learn library's standard methods, calculated evaluation parameters- Precision, Recall, F1 Score.
	Evaluation of indicBERT	:
		Imported NER tags pickel file generated by indicBERT fine-tuned model while doing Question 2 for the said 25 questions.
		Using sicket-learn library's standard methods, calculated evaluation parameters- Precision, Recall, F1 Score.
	Evaluation of ChatGPT	:
		Imported ChatGPT generated NER tags.
		Using sicket-learn library's standard methods, calculated evaluation parameters- Precision, Recall, F1 Score.
	For all the 3 evaluations, I used manually tagged NER tags as ground truth.
Question 5:
	Detailed report given in pdf.

Note: Question 1, 3 and 4 are in Single python notebook, while Q2 has 2 python notebooks. For Q5, a pdf copy has been submitted
